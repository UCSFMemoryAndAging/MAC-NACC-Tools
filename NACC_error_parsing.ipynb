{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will parse the report returned to you, once you choose 'Finalize All' in the Finalize area of the NACC portal.\n",
    "\n",
    "This Finalization report which will be parsed has all of the error information related to your stuck packets -- visit numbers, forms, etc, along with the actual error text. \n",
    "\n",
    "(Keep in mind, however, this won't get one particular class of errors. The final error check by the NACC, called the Cross Visit error check, is done by the NACC in a separate sequential step, the results of which come in a second email delivered after Finalize All is submitted. So, this script will retrieve a center's Within Form and Cross Form errors only. Fortunately, this is usually the bulk of the errors.) \n",
    "\n",
    "To create a csv of the MAC's errors:\n",
    " -  first log on to the NACC portal, and navigate to the Error Check sidebar, within the FTD UDS Submission area.\n",
    " -  Select \"All Packets\" and set 'Select Number of Errors to Display:' to 'All Errors'. No need to create an excel file.\n",
    " -  Choose the 'Batch Job' option, enter your email, submit and wait for the first response email.\n",
    " \n",
    "When you get the email back (titled 'UDS Data Final Checks'), click on the attached link to open in your default browser.\n",
    "\n",
    "Find and right click the 'Print File' link on the webpage, and save as 'ferrorNN.pff'.\n",
    "Now, open in Sublime and save as a csv (this is the least painful way to retain formatting). Make sure the error report is in the same directory that this script lives in.\n",
    "\n",
    "Finally, run this script and find the outputted .csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read file; perform basic cleaning\n",
    "# Remember, you must get a file name 'ferrorNN.pff' after finalizing (check the first email and open in browser: right click the link and save this locally)\n",
    "# Open in Sublime text editor or whatever editor you prefer, and save as a .csv. \n",
    "# Then set the name here so that you can open it.\n",
    "\n",
    "df = []\n",
    "with open('ferrorXX.csv', 'U') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        df.append(row)                      # Each row is a list\n",
    "\n",
    "df = [alist for alist in df if alist != []] # Remove empty lists (these are corresponding to blank lines in the ferror.csv)\n",
    "\n",
    "df1 = [[' '.join(alist)] for alist in df]           # For each list, rejoin the strings inside if there are more than one. This keeps the error messages together in one string, which may have been split on commas when the file was read in (as some error messages contain commas).\n",
    "df2 = [item for sublist in df1 for item in sublist] # Flatten our list of lists; now we have one list, where each string inside is one complete row just as you would find on the csv \n",
    "df3 = [astring.strip() for astring in df2]          # Strip whitespace from the beginning and end of each string / error message\n",
    "df4 = [astring.strip().split() for astring in df3]\n",
    "df5 = [' '.join(alist) for alist in df4] \n",
    "\n",
    "# At this point, we should have one list of strings, where each string is a line from the ferrror.csv file, with excess whitespace removed and commas within the error removed.\n",
    "\n",
    "df5[:5]\n",
    "\n",
    "# Continue with cleaning and prep within a Pandas DataFrame\n",
    "df = pd.DataFrame(df5)\n",
    "\n",
    "mask = df.applymap(lambda x: x is None) # replace all None with ''\n",
    "cols = df.columns[(mask).any()]\n",
    "for col in df[cols]:\n",
    "    df.loc[mask[col], col] = ''\n",
    "    \n",
    "df = pd.DataFrame(df.iloc[1:].apply(lambda x: ''.join(x), axis=1)) # This collapses all columns into one column -- later we deconstruct this single column into all others\n",
    "df.columns = ['data']                                            # Name this single column 'data'\n",
    "\n",
    "# Remove header: this is the first block on the csv that shows site number and the (erroneous, by the way) report of numbers of packets in the working database.\n",
    "# The errors we want start after the line \"All packets processed!\"\n",
    "first_row_idx = df[df.data.str.match('All packets processed!')].index[0] +1\n",
    "df = df.loc[first_row_idx:, ]\n",
    "\n",
    "df['data'] = df['data'].map(str.strip) # We want to make sure there is only one whitespace between every token\n",
    "\n",
    "# Remove footer, which has no useful information for the purpose of creating this report:\n",
    "last_row_idx = df[df.data.str.match('The following Packets have not been moved to the current database')].index[0] -1\n",
    "df = df.loc[:last_row_idx, ]\n",
    "\n",
    "# Remove all empty lines and lines that have only --------------------------------------------------------------------------------------------------\n",
    "df = df[df.data != '--------------------------------------------------------------------------------------------------']\n",
    "df = df[df.data != '']\n",
    "df = df[df.data !=\n",
    "        'Item       Data Element E-#  Error                                                      Value']\n",
    "df = df[df.data != 'Item       Data Element E-#  Error                               Var Comp      Value']\n",
    "df = df[df.data != 'Item       Data Element E-#  Error                               Value         Cross with ']\n",
    "df = df[df.data != 'Item       Data Element  E-# Error                                   Var Comp  Value']\n",
    "df = df[df.data != 'All packets processed!']\n",
    "\n",
    "##### we are ready to start creating the full dataframe by using a strategy of creating fresh columns and copying \n",
    "# the appropriate info over from 'data' column, then ffilling ('fill forward') down.\n",
    "# This is the general strategy: use matching to find the information we want, then create a new column out of it.\n",
    "# We take advantage of the fact that the NACC's error messages have (for the most part) fixed character lengths. \n",
    "# This means the PIDN, message, type, variable, etc, all occupy a fixed position and length within each row of the 'data' column.\n",
    "# Ultimately, we will delete the 'data' column when it has all valuable information copied into other columns.\n",
    "\n",
    "## Start with PIDN. This creates a PIDN column.\n",
    "df['PIDN'] = np.where(df.data.str.match('Patient ID'), df.data.str.split(' ').str.get(2), None)\n",
    "df['PIDN'] = df['PIDN'].fillna(method =\"ffill\")\n",
    "\n",
    "# Visit\n",
    "df['Visit'] = np.where(df.data.str.match('Patient ID'), df.data.str.split(' ').str.get(5), None)\n",
    "df['Visit'] = df['Visit'].fillna(method =\"ffill\")\n",
    "\n",
    "## ErrorCategory\n",
    "df['ErrorCategory'] = None\n",
    "df['ErrorCategory'] = np.where(df.data.str.match('Within Form Error Checks'), 'Within Form Error', df['ErrorCategory']) \n",
    "df['ErrorCategory'] = np.where(df.data.str.match('Cross Form Error Checks'), 'Cross Form Error', df['ErrorCategory']) \n",
    "df['ErrorCategory'] = np.where(df.data.str.match('Cross Visit'), 'Cross Visit', df['ErrorCategory'])\n",
    "df['ErrorCategory'] = np.where(df.data.str.match('Range Checks'), 'Within Form Error Checks', df['ErrorCategory'])\n",
    "df['ErrorCategory'] = np.where(df.data.str.match('Missing Form'), 'Cross Form Error', df['ErrorCategory'])\n",
    "df['ErrorCategory'] = np.where(df.data.str.match('Packet Mismatch'), 'Cross Form Error', df['ErrorCategory']) \n",
    "df['ErrorCategory'] = df['ErrorCategory'].fillna(method =\"ffill\")\n",
    "\n",
    "# ErrorType: start with Alerts. Shift them up by one since the NACC prints them after the alerts are shown\n",
    "df['ErrorType'] = '' # creates an empty column\n",
    "df['ErrorType'] = np.where(df.data.str.match('Verify this alert'), 'Alerts', df['ErrorType']) \n",
    "df.ErrorType = df.ErrorType.shift(-1)\n",
    "\n",
    "df['ErrorType'] = np.where((df.ErrorCategory.str.match('Within') & df.ErrorType.str.match('(?!Alerts)')), 'Error Checks', df['ErrorType'])\n",
    "df['ErrorType'] = np.where((df.ErrorCategory.str.match('Cross Form Error') & df.ErrorType.str.match('(?!Alerts)')), 'Error Checks', df['ErrorType']) \n",
    "df['ErrorType'] = np.where((df.ErrorCategory.str.match('Cross Visit') & df.ErrorType.str.match('(?!Alerts)')), 'Error Checks', df['ErrorType']) \n",
    "\n",
    "## ErrorType: find 'Found Not Missing'. Haven't tested this since our center doesn't have any on our error report.\n",
    "df['ErrorType'] = np.where((df.data.str.match('Found Not Missing') & df.ErrorType.str.match('(?!Alerts)')), 'Found Not Missing', df['ErrorType'])\n",
    "\n",
    "## ErrorType: find 'Verified And Not Approved'. Haven't tested this since our center doesn't have any on our error report.\n",
    "df['ErrorType'] = np.where((df.data.str.match('Verified And Not Approved') & df.ErrorType.str.match('(?!Alerts)')), 'Error Checks', df['ErrorType'])\n",
    "\n",
    "# Form column. This is a bit different than the previous strategy. Using regex, if `data` starts with 2 non-spaces and is followed by a space,\n",
    "# we take that as the Form ID information, eg, 'B4 '.\n",
    "\n",
    "# Here we also get the Forms that are missing for Missing Form(s) errors.\n",
    "df['Form'] = ''\n",
    "df.Form.loc[df[df.data.str.match('^\\S{2}\\s+')].index] = df.data.str.split(' ').str.get(0) # Matches UDS  forms that are 2 characters in length (e.g., 'C1')\n",
    "df.Form.loc[df[df.data.str.match('^\\S{3}\\s+')].index] = df.data.str.split(' ').str.get(0) # Matches FTLD forms that are 3 characters in length (e.g., 'C2F')\n",
    "df.Form.loc[df[df.data.str.match('Missing Form')].index] = df.data.str.replace('Missing Form\\(s\\): ', '')\n",
    "df.Form.loc[df[df.data.str.match('F packet Version 3 must have a C1 or C2 form')].index] = 'C1 C2'\n",
    "df.Form.loc[df[df.data.str.match('Version 3 Missing Form')].index] = 'C1 C2'\n",
    "df.Form.loc[df[df.data.str.match('Form present indicated missing on Z1')].index] = df.data.str.split(' ').str.get(-1)\n",
    "\n",
    "# Field column. Same regex as above; just grabbing the next character as the Field. Relying on the NACC having consistent fields in their error messages.\n",
    "df['Field'] = '' \n",
    "df.Field.loc[df[df.data.str.match('^\\S{2}\\s+')].index] = df.data.str.split(' ').str.get(1) # Matches UDS  forms that are 2 characters in length\n",
    "df.Field.loc[df[df.data.str.match('^\\S{3}\\s+')].index] = df.data.str.split(' ').str.get(1) # Matches FTLD forms that are 3 characters in length\n",
    "\n",
    "# Varname column. \n",
    "df['Varname'] = ''\n",
    "df.Varname.loc[df[df.data.str.match('^\\S{2}\\s+')].index] = df.data.str.split(' ').str.get(2) # as above for Field and Form\n",
    "df.Varname.loc[df[df.data.str.match('^\\S{3}\\s+')].index] = df.data.str.split(' ').str.get(2) # as above for Field and Form\n",
    "df.Varname.loc[df[df.data.str.match('Missing Form')].index] = ''            # Varname is not relevant for Missing Form(s) so set to blank\n",
    "df.Varname.loc[df[df.data.str.match('Packet Mismatch')].index] = 'PACKET'   # This is a custom label made by us to help with error labeling...not from the NACC.\n",
    "\n",
    "# ErrorCode column. Similar idea as above.\n",
    "df['ErrorCode'] = ''\n",
    "df.ErrorCode.loc[df[df.data.str.match('^\\S{2}\\s+')].index] = df.data.str.split(' ').str.get(3)\n",
    "df.ErrorCode.loc[df[df.data.str.match('^\\S{3}\\s+')].index] = df.data.str.split(' ').str.get(3)\n",
    "df.ErrorCode.loc[df[df.data.str.match('Missing Form')].index] = ''\n",
    "\n",
    "## Packet. This was troublesome; the best solution was to do a string replace then split and str.get and ffill\n",
    "df.data = df.data.str.replace('Packet\\: FTLD Module Initial', ' IF ')\n",
    "df.data = df.data.str.replace('Packet\\: FTLD Module Followup', ' FF ')\n",
    "\n",
    "df['Packet'] = np.where(df.data.str.match('Patient ID'), df.data.str.split(' ').str.get(7), None)\n",
    "\n",
    "\n",
    "df['Packet'] = df['Packet'].fillna(method =\"ffill\")\n",
    "\n",
    "# Remove rows no longer necessary from the original 'data' column that have been munged\n",
    "df = df[df.data !='Range Checks']\n",
    "df = df[df.data !='Item Data Element E-# Error Value']\n",
    "df = df[df.data !='Item Data Element E-# Error Var Comp Value']\n",
    "df = df[df.data !='Within Form Error Checks']\n",
    "df = df[df.data !='Cross Form Alerts']\n",
    "df = df[df.data !='Within Form Alerts']\n",
    "df = df[df.data !='Verify this alert'] \n",
    "df = df[df.data !='Cross Form Error Checks']\n",
    "df = df[df.data !='Item Data Element E-# Error Value Cross with']\n",
    "\n",
    "# Time for ErrorText. This is the most involved part; there are many edgecases due to inconsistent formatting of the error messages by the NACC.\n",
    "# Luckly, most NACC errors start with 4 fields, then comes the error text itself. \n",
    "df['ErrorText'] = None \n",
    "\n",
    "# First, fix an edge case: an error with 0 fields before the error message\n",
    "df.data[df.data.str.startswith('Version 3 Missing Form(s): ')]= df.data.str.replace('Version 3 Missing Form\\(s\\)\\:', '1 2 3 4 Version 3 Missing Form(s):') \n",
    "\n",
    "# If a NACC error doesn't have 4 fields before the actual message begins, prepend the text so that it fits this rule\n",
    "desc1 = []\n",
    "for astring in list(df.data):\n",
    "   # print len(astring.split())\n",
    "    if len(astring.split()) >=4:\n",
    "        desc1.append(' '.join(astring.split()[4:]))\n",
    "    else:\n",
    "        desc1.append('1 2 3 4 5')\n",
    "        \n",
    "df['ErrorText'] = desc1\n",
    "df.ErrorText.loc[df[df.data.str.match('Missing Form')].index] = df.data\n",
    "\n",
    "# Some extra, one-off cleaning for odd situations, to make the ErrorText column cleaner\n",
    "df.ErrorText = df.ErrorText.str.replace('Error: ', '') \n",
    "df.ErrorText = df.ErrorText.str.replace('Alert: ', '')\n",
    "df.ErrorText = df.ErrorText.str.replace('mismatch', 'Packet mismatch: ') \n",
    "\n",
    "df.ErrorText = df.ErrorText.str.replace('on Z1\\:', 'Form present indicated missing on Z1: ')\n",
    "df.ErrorText = df.ErrorText.str.replace('on Z1F\\:', 'Form present indicated missing on Z1F: ')\n",
    "df.ErrorText = df.ErrorText.str.replace('Version 3 Missing Form(s): C1 C2', 'C1 C2')\n",
    "df.ErrorText = df.ErrorText.str.replace('date after Module', 'Scan date after Module')\n",
    "df.ErrorText = df.ErrorText.str.replace('must have a C1 or C2 form', 'F packet Version 3 must have a C1 or C2 form')\n",
    "\n",
    "# Some errors need to have Var replaced at this point in the dataframe's creation\n",
    "df.ErrorText = df.ErrorText.str.replace('must have a C1 or C2 form', 'F packet Version 3 must have a C1 or C2 form')\n",
    "df.ErrorText = df.ErrorText.str.replace('have an etiologic diagnosis', 'Must have an etiologic diagnosis')\n",
    "df.ErrorText = df.ErrorText.str.replace('a-e must be filled or empty', 'Items a-e must be filled or empty')\n",
    "\n",
    "\n",
    "# To make it easier to read, change ErrorCategory values of 'Within Form Error Checks' or 'Within Form Checks' or 'Within Form Error' to 'Within Form',\n",
    "# and change 'Cross Form Error' to 'Cross Form'\n",
    "df.ErrorCategory = df.ErrorCategory.str.replace('Within Form Error', 'Within Form')\n",
    "df.ErrorCategory = df.ErrorCategory.str.replace('Within Form Checks', 'Within Form')\n",
    "df.ErrorCategory = df.ErrorCategory.str.replace('Within Form Error Checks', 'Within Form')\n",
    "df.ErrorCategory = df.ErrorCategory.str.replace('Cross Form Error', 'Cross Form')\n",
    "\n",
    "# Final removal of unwanted rows and the 'data' column itself\n",
    "df = df[~df.data.str.match('^Patient ID')]\n",
    "df = df.drop('data', axis=1)\n",
    "\n",
    "# One-off cleanups of the error text\n",
    "df.ErrorText[df.ErrorText.str.startswith('of')] = df.ErrorText.str.replace('of ', 'Value of ') \n",
    "\n",
    "# convert datatype in case you want to merge later on some other table you read into pandas\n",
    "df.PIDN = df.PIDN.astype('int')\n",
    "\n",
    "#uncomment to write a csv, don't forget the appropriate path\n",
    "df.to_csv('error_report.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
